{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_qNSzzyaCbD"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:20.472578Z",
     "iopub.status.busy": "2022-12-14T13:53:20.472280Z",
     "iopub.status.idle": "2022-12-14T13:53:20.476866Z",
     "shell.execute_reply": "2022-12-14T13:53:20.476134Z"
    },
    "id": "jmjh290raIky"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Neural machine translation with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOpGoE2T-YXS"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/text/tutorials/nmt_with_attention\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/nmt_with_attention.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/nmt_with_attention.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/docs/tutorials/nmt_with_attention.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xh8WNEwYA3BW"
   },
   "source": [
    "This tutorial demonstrates how to train a sequence-to-sequence (seq2seq) model for Spanish-to-English translation roughly based on [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025v5) (Luong et al., 2015). \n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=400 src=\"https://www.tensorflow.org/images/tutorials/transformer/RNN%2Battention-words-spa.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th colspan=1>This tutorial: An encoder/decoder connected by attention.</th>\n",
    "<tr>\n",
    "</table>\n",
    "\n",
    "While this architecture is somewhat outdated, it is still a very useful project to work through to get a deeper understanding of sequence-to-sequence models and attention mechanisms (before going on to [Transformers](transformer.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiwtNgENbx2g"
   },
   "source": [
    "\n",
    "\n",
    "This example assumes some knowledge of TensorFlow fundamentals below the level of a Keras layer:\n",
    "  * [Working with tensors](https://www.tensorflow.org/guide/tensor) directly\n",
    "  * [Writing custom `keras.Model`s and `keras.layers`](https://www.tensorflow.org/guide/keras/custom_layers_and_models)\n",
    "\n",
    "After training the model in this notebook, you will be able to input a Spanish sentence, such as \"*Â¿todavia estan en casa?*\", and return the English translation: \"*are you still at home?*\"\n",
    "\n",
    "The resulting model is exportable as a `tf.saved_model`, so it can be used in other TensorFlow environments.\n",
    "\n",
    "The translation quality is reasonable for a toy example, but the generated attention plot is perhaps more interesting. This shows which parts of the input sentence has the model's attention while translating:\n",
    "\n",
    "<img src=\"https://tensorflow.org/images/spanish-english.png\" alt=\"spanish-english attention plot\">\n",
    "\n",
    "Note: This example takes approximately 10 minutes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAmSR1FaqKrl"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:20.480963Z",
     "iopub.status.busy": "2022-12-14T13:53:20.480297Z",
     "iopub.status.idle": "2022-12-14T13:53:24.238557Z",
     "shell.execute_reply": "2022-12-14T13:53:24.237691Z"
    },
    "id": "DGFTkuRvzWqc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text>=2.10 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow<2.12,>=2.11.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-text>=2.10) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-text>=2.10) (0.12.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.12.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.10.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (14.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (58.0.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.27.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (22.10.26)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.32.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.21.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.11.0)\n",
      "Requirement already satisfied: packaging in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.14.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.26.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text>=2.10) (3.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (0.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"tensorflow-text>=2.10\"\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:24.243288Z",
     "iopub.status.busy": "2022-12-14T13:53:24.242555Z",
     "iopub.status.idle": "2022-12-14T13:53:26.697361Z",
     "shell.execute_reply": "2022-12-14T13:53:26.696646Z"
    },
    "id": "tnxXKDjq3jEL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 14:58:52.050685: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_yq8kvIqoqQ"
   },
   "source": [
    "This tutorial uses a lot of low level API's where it's easy to get shapes wrong. This class is used to check shapes throughout the tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:26.701805Z",
     "iopub.status.busy": "2022-12-14T13:53:26.700963Z",
     "iopub.status.idle": "2022-12-14T13:53:26.706955Z",
     "shell.execute_reply": "2022-12-14T13:53:26.706105Z"
    },
    "id": "KqFqKi4fqN9X"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "class ShapeChecker():\n",
    "  def __init__(self):\n",
    "    # Keep a cache of every axis-name seen\n",
    "    self.shapes = {}\n",
    "\n",
    "  def __call__(self, tensor, names, broadcast=False):\n",
    "    if not tf.executing_eagerly():\n",
    "      return\n",
    "\n",
    "    parsed = einops.parse_shape(tensor, names)\n",
    "\n",
    "    for name, new_dim in parsed.items():\n",
    "      old_dim = self.shapes.get(name, None)\n",
    "      \n",
    "      if (broadcast and new_dim == 1):\n",
    "        continue\n",
    "\n",
    "      if old_dim is None:\n",
    "        # If the axis name is new, add its length to the cache.\n",
    "        self.shapes[name] = new_dim\n",
    "        continue\n",
    "\n",
    "      if new_dim != old_dim:\n",
    "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                         f\"    found: {new_dim}\\n\"\n",
    "                         f\"    expected: {old_dim}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjUROhJfH3ML"
   },
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puE_K74DIE9W"
   },
   "source": [
    "The tutorial uses a language dataset provided by [Anki](http://www.manythings.org/anki/). This dataset contains language translation pairs in the format:\n",
    "\n",
    "```\n",
    "May I borrow this book?\tÂ¿Puedo tomar prestado este libro?\n",
    "```\n",
    "\n",
    "They have a variety of languages available, but this example uses the English-Spanish dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfodePkj3jEa"
   },
   "source": [
    "### Download and prepare the dataset\n",
    "\n",
    "For convenience, a copy of this dataset is hosted on Google Cloud, but you can also download your own copy. After downloading the dataset, here are the steps you need to take to prepare the data:\n",
    "\n",
    "1. Add a *start* and *end* token to each sentence.\n",
    "2. Clean the sentences by removing special characters.\n",
    "3. Create a word index and reverse word index (dictionaries mapping from word â id and id â word).\n",
    "4. Pad each sentence to a maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:26.710535Z",
     "iopub.status.busy": "2022-12-14T13:53:26.709875Z",
     "iopub.status.idle": "2022-12-14T13:53:26.852614Z",
     "shell.execute_reply": "2022-12-14T13:53:26.851762Z"
    },
    "id": "kRVATYOgJs1b"
   },
   "outputs": [],
   "source": [
    "# Download the file\n",
    "import pathlib\n",
    "path_to_file = pathlib.Path('../data/gloss-text-augmented.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:26.856293Z",
     "iopub.status.busy": "2022-12-14T13:53:26.855695Z",
     "iopub.status.idle": "2022-12-14T13:53:26.860524Z",
     "shell.execute_reply": "2022-12-14T13:53:26.859728Z"
    },
    "id": "OHn4Dct23jEm"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "  text = path.read_text(encoding='utf-8')\n",
    "\n",
    "  lines = text.splitlines()\n",
    "  pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "#   context = np.array([context.lower() for context,target in pairs])\n",
    "#   target = np.array([target.lower() for context,target in pairs])\n",
    "  context = np.array([context.lower() for target,context in pairs])\n",
    "  target = np.array([target.lower() for target,context in pairs])\n",
    "\n",
    "  return target, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:26.863774Z",
     "iopub.status.busy": "2022-12-14T13:53:26.863146Z",
     "iopub.status.idle": "2022-12-14T13:53:27.384149Z",
     "shell.execute_reply": "2022-12-14T13:53:27.383109Z"
    },
    "id": "cTbSbBz55QtF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i eat an orange\n"
     ]
    }
   ],
   "source": [
    "target, context = load_data(path_to_file)\n",
    "print(context[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:27.388169Z",
     "iopub.status.busy": "2022-12-14T13:53:27.387490Z",
     "iopub.status.idle": "2022-12-14T13:53:27.391883Z",
     "shell.execute_reply": "2022-12-14T13:53:27.391094Z"
    },
    "id": "lH_dPY8TRp3c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat orange\n"
     ]
    }
   ],
   "source": [
    "print(target[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43855\n"
     ]
    }
   ],
   "source": [
    "# Divide 2/3\n",
    "threshold=len(target)//2\n",
    "target_raw,context_raw=target[:threshold],context[:threshold]\n",
    "target_pred,context_pred=target[threshold:],context[threshold:]\n",
    "print(len(target_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "### Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfVWx3WaI5Df"
   },
   "source": [
    "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:27.395550Z",
     "iopub.status.busy": "2022-12-14T13:53:27.394896Z",
     "iopub.status.idle": "2022-12-14T13:53:31.109819Z",
     "shell.execute_reply": "2022-12-14T13:53:31.109081Z"
    },
    "id": "3rZFgz69nMPa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 14:59:12.436797: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(context_raw)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:31.114119Z",
     "iopub.status.busy": "2022-12-14T13:53:31.113575Z",
     "iopub.status.idle": "2022-12-14T13:53:31.275545Z",
     "shell.execute_reply": "2022-12-14T13:53:31.274854Z"
    },
    "id": "qc6-NK1GtWQt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'i find the idea very good .' b'the sitting was closed at 11.10 p.m. '\n",
      " b'i agree entirely with this proposal .'\n",
      " b'in my opinion , asking for a temporary ceasefire is irresponsible with regard to the people concerned .'\n",
      " b'we often confuse dialogue with citizens with dialogue with organisations either wholly or partly funded by the commission .'], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b'x-i find idea desc-very desc-good .'\n",
      " b'sit be desc-close at 11.10 desc-p.m.'\n",
      " b'x-i agree desc-entirely with this proposal .'\n",
      " b'in x-my opinion , ask for desc-temporary ceasefire be desc-irresponsible with regard to people concern .'\n",
      " b'x-we desc-often confuse dialogue with citizen with dialogue with organization eir desc-wholly or desc-partly fund by commission .'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for example_context_strings, example_target_strings in train_raw.take(1):\n",
    "  print(example_context_strings[:5])\n",
    "  print()\n",
    "  print(example_target_strings[:5])\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCoxLcuN3bwv"
   },
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kwdPcHvzz_a"
   },
   "source": [
    "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOQ5n55X4uDB"
   },
   "source": [
    "#### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upKhKAMK4zzI"
   },
   "source": [
    "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
    "\n",
    "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
    "\n",
    "The `tensorflow_text` package contains a unicode normalize operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:31.279684Z",
     "iopub.status.busy": "2022-12-14T13:53:31.279165Z",
     "iopub.status.idle": "2022-12-14T13:53:31.284225Z",
     "shell.execute_reply": "2022-12-14T13:53:31.283647Z"
    },
    "id": "mD0e-DWGQ2Vo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'this be why this report be desc-devoted desc-mainly to x-y .'\n",
      "b'this be why this report be desc-devoted desc-mainly to x-y .'\n"
     ]
    }
   ],
   "source": [
    "example_text = tf.constant('this be why this report be desc-devoted desc-mainly to x-y .')\n",
    "\n",
    "print(example_text.numpy())\n",
    "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hTllEjK6RSo"
   },
   "source": [
    "Unicode normalization will be the first step in the text standardization function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:31.287728Z",
     "iopub.status.busy": "2022-12-14T13:53:31.287161Z",
     "iopub.status.idle": "2022-12-14T13:53:31.291699Z",
     "shell.execute_reply": "2022-12-14T13:53:31.291111Z"
    },
    "id": "chTF5N885F0P"
   },
   "outputs": [],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "  # Split accented characters.\n",
    "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "  text = tf.strings.lower(text)\n",
    "  # Keep space, a to z, and select punctuation.\n",
    "  text = tf.strings.regex_replace(text, '[^ a-z.?!,Â¿]', '')\n",
    "  # Add spaces around punctuation.\n",
    "  text = tf.strings.regex_replace(text, '[.?!,Â¿]', r' \\0 ')\n",
    "  # Strip whitespace.\n",
    "  text = tf.strings.strip(text)\n",
    "\n",
    "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:31.295303Z",
     "iopub.status.busy": "2022-12-14T13:53:31.294695Z",
     "iopub.status.idle": "2022-12-14T13:53:31.303568Z",
     "shell.execute_reply": "2022-12-14T13:53:31.302985Z"
    },
    "id": "UREvDg3sEKYa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this be why this report be desc-devoted desc-mainly to x-y .\n",
      "[START] this be why this report be descdevoted descmainly to xy  . [END]\n"
     ]
    }
   ],
   "source": [
    "print(example_text.numpy().decode())\n",
    "print(tf_lower_and_split_punct(example_text).numpy().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4q-sKsSI7xRZ"
   },
   "source": [
    "#### Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aKn8qd37abi"
   },
   "source": [
    "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:31.306633Z",
     "iopub.status.busy": "2022-12-14T13:53:31.306387Z",
     "iopub.status.idle": "2022-12-14T13:53:31.318888Z",
     "shell.execute_reply": "2022-12-14T13:53:31.318172Z"
    },
    "id": "eAY9k49G3jE_"
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 5000\n",
    "\n",
    "context_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kbC6ODP8IK_"
   },
   "source": [
    "The `TextVectorization` layer and many other [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fit`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:31.322181Z",
     "iopub.status.busy": "2022-12-14T13:53:31.321622Z",
     "iopub.status.idle": "2022-12-14T13:53:33.629086Z",
     "shell.execute_reply": "2022-12-14T13:53:33.628165Z"
    },
    "id": "bmsI1Yql8FYe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " '[START]',\n",
       " '[END]',\n",
       " '.',\n",
       " 'the',\n",
       " ',',\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'in',\n",
       " 'and',\n",
       " 'a',\n",
       " 'this',\n",
       " 'that',\n",
       " 'we',\n",
       " 'i',\n",
       " 'for',\n",
       " 'it',\n",
       " 'be']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
    "\n",
    "# Here are the first 10 words from the vocabulary:\n",
    "context_text_processor.get_vocabulary()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kGjIFjX8_Wp"
   },
   "source": [
    "That's the Spanish `TextVectorization` layer, now build and `.adapt()` the English one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:33.633770Z",
     "iopub.status.busy": "2022-12-14T13:53:33.633065Z",
     "iopub.status.idle": "2022-12-14T13:53:35.836766Z",
     "shell.execute_reply": "2022-12-14T13:53:35.835935Z"
    },
    "id": "jlC4xuZnKLBS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " '[START]',\n",
       " '[END]',\n",
       " '.',\n",
       " 'be',\n",
       " ',',\n",
       " 'to',\n",
       " 'xwe',\n",
       " 'in',\n",
       " 'and',\n",
       " 'this',\n",
       " 'that',\n",
       " 'xi',\n",
       " 'have',\n",
       " 'for',\n",
       " 'xit',\n",
       " 'on',\n",
       " 'descnot',\n",
       " 'will']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True)\n",
    "\n",
    "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
    "target_text_processor.get_vocabulary()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWQqlP_s9eIv"
   },
   "source": [
    "Now these layers can convert a batch of strings into a batch of token IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:35.840526Z",
     "iopub.status.busy": "2022-12-14T13:53:35.839872Z",
     "iopub.status.idle": "2022-12-14T13:53:35.889422Z",
     "shell.execute_reply": "2022-12-14T13:53:35.888738Z"
    },
    "id": "9KZxj8IrNZ9S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[2, 16, 376, 5, 669, 51, 124, 4, 3],\n",
       " [2, 5, 80, 42, 142, 32, 4, 256, 4, 178, 4, 3],\n",
       " [2, 16, 213, 1313, 26, 13, 150, 4, 3]]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tokens = context_text_processor(example_context_strings)\n",
    "example_tokens[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AA9rUn9G9n78"
   },
   "source": [
    "The `get_vocabulary` method can be used to convert token IDs back to text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:35.893034Z",
     "iopub.status.busy": "2022-12-14T13:53:35.892407Z",
     "iopub.status.idle": "2022-12-14T13:53:35.909454Z",
     "shell.execute_reply": "2022-12-14T13:53:35.908852Z"
    },
    "id": "98g9rcxGQY0I"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START] i find the idea very good . [END]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
    "tokens = context_vocab[example_tokens[0].numpy()]\n",
    "' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot0aCL9t-Ghi"
   },
   "source": [
    "The returned token IDs are zero-padded. This can easily be turned into a mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:35.912742Z",
     "iopub.status.busy": "2022-12-14T13:53:35.912188Z",
     "iopub.status.idle": "2022-12-14T13:53:36.157685Z",
     "shell.execute_reply": "2022-12-14T13:53:36.156965Z"
    },
    "id": "_jx4Or_eFRSz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mask')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(example_tokens.to_tensor())\n",
    "plt.title('Token IDs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
    "plt.title('Mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3O0B4XdFlRgc"
   },
   "source": [
    "### Process the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVCuyuSp_whd"
   },
   "source": [
    "The `process_text` function below converts the `Datasets` of strings, into  0-padded tensors of token IDs. It also converts from a `(context, target)` pair to an `((context, target_in), target_out)` pair for training with `keras.Model.fit`. Keras expects `(inputs, labels)` pairs, the inputs are the `(context, target_in)` and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to eachother, so that at each location the label is the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:36.161705Z",
     "iopub.status.busy": "2022-12-14T13:53:36.161123Z",
     "iopub.status.idle": "2022-12-14T13:53:36.376562Z",
     "shell.execute_reply": "2022-12-14T13:53:36.375836Z"
    },
    "id": "wk5tbZWQl5u1"
   },
   "outputs": [],
   "source": [
    "def process_text(context, target):\n",
    "  context = context_text_processor(context).to_tensor()\n",
    "  target = target_text_processor(target)\n",
    "  targ_in = target[:,:-1].to_tensor()\n",
    "  targ_out = target[:,1:].to_tensor()\n",
    "  return (context, targ_in), targ_out\n",
    "\n",
    "\n",
    "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
    "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iGi7X2m_tbM"
   },
   "source": [
    "Here is the first sequence of each, from the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:36.380626Z",
     "iopub.status.busy": "2022-12-14T13:53:36.380088Z",
     "iopub.status.idle": "2022-12-14T13:53:36.595128Z",
     "shell.execute_reply": "2022-12-14T13:53:36.594462Z"
    },
    "id": "woQBWAjLsJkr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2  15  22  12  51 155 233 290  91 323]\n",
      "\n",
      "[  2   8  14  46 151 254 182  87 314  15]\n",
      "[  8  14  46 151 254 182  87 314  15 459]\n"
     ]
    }
   ],
   "source": [
    "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
    "  print(ex_context_tok[0, :10].numpy()) \n",
    "  print()\n",
    "  print(ex_tar_in[0, :10].numpy()) \n",
    "  print(ex_tar_out[0, :10].numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNfHIF71ulLu"
   },
   "source": [
    "## The encoder/decoder\n",
    "\n",
    "The following diagrams shows an overview of the model. In both the encoder is on the left, the decoder is on the right. At each time-step the decoder's output is combined with the encoder's output, to predict the next word. \n",
    "\n",
    "The original [left] contains a few extra connections that are intentionally omitted from this tutorial's model [right], as they are generally unnecessary, and difficult to implement. Those missing connections are:\n",
    "\n",
    "1. Feeding the state from the encoder's RNN to the decoder's RNN\n",
    "2. Feeding the attention output back to the RNN's input.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=500 src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\"/>\n",
    "  </td>\n",
    "  <td>\n",
    "   <img width=380 src=\"https://www.tensorflow.org/images/tutorials/transformer/RNN+attention.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th colspan=1>The original from <a href=https://arxiv.org/abs/1508.04025v5>Effective Approaches to Attention-based Neural Machine Translation</a></th>\n",
    "  <th colspan=1>This tutorial's model</th>\n",
    "<tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzQWx2saImMV"
   },
   "source": [
    "Before getting into it define constants for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:36.599307Z",
     "iopub.status.busy": "2022-12-14T13:53:36.598631Z",
     "iopub.status.idle": "2022-12-14T13:53:36.602039Z",
     "shell.execute_reply": "2022-12-14T13:53:36.601401Z"
    },
    "id": "_a9uNz3-IrF-"
   },
   "outputs": [],
   "source": [
    "UNITS = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blNgVbLSzpsr"
   },
   "source": [
    "### The encoder\n",
    "\n",
    "The goal of the encoder is to process the context sequence into a sequence of vectors that are useful for the decoder as it attempts to predict the next output for each timestep. Since the context sequence is constant, there is no restriction on how information can flow in the encoder, so use a bidirectional-RNN to do the processing:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=500 src=\"https://tensorflow.org/images/tutorials/transformer/RNN-bidirectional.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>A bidirectional RNN</th>\n",
    "<tr>\n",
    "</table>\n",
    "\n",
    "The encoder:\n",
    "\n",
    "1. Takes a list of token IDs (from `context_text_processor`).\n",
    "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
    "4. Processes the embeddings into a new sequence (Using a bidirectional `layers.GRU`).\n",
    "5. Returns the processed sequence. This will be passed to the attention head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:36.605407Z",
     "iopub.status.busy": "2022-12-14T13:53:36.604915Z",
     "iopub.status.idle": "2022-12-14T13:53:36.611486Z",
     "shell.execute_reply": "2022-12-14T13:53:36.610923Z"
    },
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, text_processor, units):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.text_processor = text_processor\n",
    "    self.vocab_size = text_processor.vocabulary_size()\n",
    "    self.units = units\n",
    "    \n",
    "    # The embedding layer converts tokens to vectors\n",
    "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
    "                                               mask_zero=True)\n",
    "\n",
    "    # The RNN layer processes those vectors sequentially.\n",
    "    self.rnn = tf.keras.layers.Bidirectional(\n",
    "        merge_mode='sum',\n",
    "        layer=tf.keras.layers.GRU(units,\n",
    "                            # Return the sequence and state\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "  def call(self, x):\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(x, 'batch s')\n",
    "\n",
    "    # 2. The embedding layer looks up the embedding vector for each token.\n",
    "    x = self.embedding(x)\n",
    "    shape_checker(x, 'batch s units')\n",
    "\n",
    "    # 3. The GRU processes the sequence of embeddings.\n",
    "    x = self.rnn(x)\n",
    "    shape_checker(x, 'batch s units')\n",
    "\n",
    "    # 4. Returns the new sequence of embeddings.\n",
    "    return x\n",
    "\n",
    "  def convert_input(self, texts):\n",
    "    texts = tf.convert_to_tensor(texts)\n",
    "    if len(texts.shape) == 0:\n",
    "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
    "    context = self.text_processor(texts).to_tensor()\n",
    "    context = self(context)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3SKkaQeGn-Q"
   },
   "source": [
    "Try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:36.615068Z",
     "iopub.status.busy": "2022-12-14T13:53:36.614428Z",
     "iopub.status.idle": "2022-12-14T13:53:37.303226Z",
     "shell.execute_reply": "2022-12-14T13:53:37.302546Z"
    },
    "id": "60gSVh05Jl6l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context tokens, shape (batch, s): (64, 22)\n",
      "Encoder output, shape (batch, s, units): (64, 22, 256)\n"
     ]
    }
   ],
   "source": [
    "# Encode the input sequence.\n",
    "encoder = Encoder(context_text_processor, UNITS)\n",
    "ex_context = encoder(ex_context_tok)\n",
    "\n",
    "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! open ~/opt/anaconda3/lib/python3.8/site-packages/einops/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45xM_Gl1MgXY"
   },
   "source": [
    "### The attention layer\n",
    "\n",
    "The attention layer lets the decoder access the information extracted by the encoder. It computes a vector from the entire context sequence, and adds that to the decoder's output. \n",
    "\n",
    "The simplest way you could calculate a single vector from the entire sequence would be to take the average across the sequence (`layers.GlobalAveragePooling1D`). An attention layer is similar, but calculates a **weighted** average across the context sequence. Where the weights are calculated from the combination of context and \"query\" vectors.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=500 src=\"https://www.tensorflow.org/images/tutorials/transformer/CrossAttention-new-full.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th colspan=1>The attention layer</th>\n",
    "<tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.307080Z",
     "iopub.status.busy": "2022-12-14T13:53:37.306521Z",
     "iopub.status.idle": "2022-12-14T13:53:37.312683Z",
     "shell.execute_reply": "2022-12-14T13:53:37.312023Z"
    },
    "id": "-Ql3ymqwD8LS"
   },
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "  def call(self, x, context):\n",
    "    shape_checker = ShapeChecker()\n",
    " \n",
    "    shape_checker(x, 'batch t units')\n",
    "    shape_checker(context, 'batch s units')\n",
    "\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "    \n",
    "    shape_checker(x, 'batch t units')\n",
    "    shape_checker(attn_scores, 'batch heads t s')\n",
    "    \n",
    "    # Cache the attention scores for plotting later.\n",
    "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
    "    shape_checker(attn_scores, 'batch t s')\n",
    "    self.last_attention_weights = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.315939Z",
     "iopub.status.busy": "2022-12-14T13:53:37.315467Z",
     "iopub.status.idle": "2022-12-14T13:53:37.468755Z",
     "shell.execute_reply": "2022-12-14T13:53:37.468036Z"
    },
    "id": "7y7hjPkNMmHh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context sequence, shape (batch, s, units): (64, 22, 256)\n",
      "Target sequence, shape (batch, t, units): (64, 20, 256)\n",
      "Attention result, shape (batch, t, units): (64, 20, 256)\n",
      "Attention weights, shape (batch, t, s):    (64, 20, 22)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = CrossAttention(UNITS)\n",
    "\n",
    "# Attend to the encoded tokens\n",
    "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
    "                                  output_dim=UNITS, mask_zero=True)\n",
    "ex_tar_embed = embed(ex_tar_in)\n",
    "\n",
    "result = attention_layer(ex_tar_embed, ex_context)\n",
    "\n",
    "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
    "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
    "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
    "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx9fUhi3Pmwp"
   },
   "source": [
    "The attention weights will sum to `1` over the context sequence, at each location in the target sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.472854Z",
     "iopub.status.busy": "2022-12-14T13:53:37.472230Z",
     "iopub.status.idle": "2022-12-14T13:53:37.478239Z",
     "shell.execute_reply": "2022-12-14T13:53:37.477607Z"
    },
    "id": "zxyR7cmQPn9P"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.0000001 , 1.        , 1.        ,\n",
       "       1.0000001 , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.9999999 , 0.99999994, 1.0000001 ,\n",
       "       1.0000001 , 1.0000001 , 1.0000001 , 1.0000001 , 1.0000001 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AagyXMH-Jhqt"
   },
   "source": [
    "\n",
    "\n",
    "Here are the attention weights across the context sequences at `t=0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.481565Z",
     "iopub.status.busy": "2022-12-14T13:53:37.481145Z",
     "iopub.status.idle": "2022-12-14T13:53:37.715882Z",
     "shell.execute_reply": "2022-12-14T13:53:37.715248Z"
    },
    "id": "Rqr8XGsAJlf6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_weights = attention_layer.last_attention_weights\n",
    "mask=(ex_context_tok != 0).numpy()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
    "plt.title('Attention weights')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(mask)\n",
    "plt.title('Mask');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Eil-C_NN1rp"
   },
   "source": [
    "Because of the small-random initialization the attention weights are initially all close to `1/(sequence_length)`. The model will learn to make these less uniform as training progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ638eHN4iCK"
   },
   "source": [
    "### The decoder\n",
    "\n",
    "The decoder's job is to generate predictions for the next token at each location in the target sequence.\n",
    "\n",
    "1. It looks up embeddings for each token in the target sequence.\n",
    "2. It uses an RNN to process the target sequence, and keep track of what it has generated so far.\n",
    "3. It uses RNN output as the \"query\" to the attention layer, when attending to the encoder's output.\n",
    "4. At each location in the output it predicts the next token.\n",
    "\n",
    "When training, the model predicts the next word at each location. So it's important that the information only flows in one direction through the model. The decoder uses a unidirectional (not bidirectional) RNN to process the target sequence.\n",
    "\n",
    "When running inference with this model it produces one word at a time, and those are fed back into the model.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=500 src=\"https://tensorflow.org/images/tutorials/transformer/RNN.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "<tr>\n",
    "  <th>A unidirectional RNN</th>\n",
    "<tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZsQJMqNmg_L"
   },
   "source": [
    "Here is the `Decoder` class' initializer. The initializer creates all the necessary layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.719773Z",
     "iopub.status.busy": "2022-12-14T13:53:37.719277Z",
     "iopub.status.idle": "2022-12-14T13:53:37.725677Z",
     "shell.execute_reply": "2022-12-14T13:53:37.725101Z"
    },
    "id": "erYvHIgAl8kh"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def __init__(self, text_processor, units):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.text_processor = text_processor\n",
    "    self.vocab_size = text_processor.vocabulary_size()\n",
    "    self.word_to_id = tf.keras.layers.StringLookup(\n",
    "        vocabulary=text_processor.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]')\n",
    "    self.id_to_word = tf.keras.layers.StringLookup(\n",
    "        vocabulary=text_processor.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]',\n",
    "        invert=True)\n",
    "    self.start_token = self.word_to_id('[START]')\n",
    "    self.end_token = self.word_to_id('[END]')\n",
    "\n",
    "    self.units = units\n",
    "\n",
    "\n",
    "    # 1. The embedding layer converts token IDs to vectors\n",
    "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
    "                                               units, mask_zero=True)\n",
    "\n",
    "    # 2. The RNN keeps track of what's been generated so far.\n",
    "    self.rnn = tf.keras.layers.GRU(units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    # 3. The RNN output will be the query for the attention layer.\n",
    "    self.attention = CrossAttention(units)\n",
    "\n",
    "    # 4. This fully connected layer produces the logits for each\n",
    "    # output token.\n",
    "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sd8-nRNzFR8x"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPnaw583CpnY"
   },
   "source": [
    "Next, the `call` method, takes 3 arguments:\n",
    "\n",
    "* `inputs` -  a `context, x` pair where:\n",
    "  * `context` - is the context from the encoder's output.\n",
    "  * `x` - is the target sequence input.\n",
    "* `state` - Optional, the previous `state` output from the decoder (the internal state of the decoder's RNN). Pass the state from a previous run to continue generating text where you left off.\n",
    "* `return_state` - [Default: False] - Set this to `True` to return the RNN state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.729209Z",
     "iopub.status.busy": "2022-12-14T13:53:37.728744Z",
     "iopub.status.idle": "2022-12-14T13:53:37.733952Z",
     "shell.execute_reply": "2022-12-14T13:53:37.733371Z"
    },
    "id": "PJOi5btHAPNK"
   },
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def call(self,\n",
    "         context, x,\n",
    "         state=None,\n",
    "         return_state=False):  \n",
    "  shape_checker = ShapeChecker()\n",
    "  shape_checker(x, 'batch t')\n",
    "  shape_checker(context, 'batch s units')\n",
    "\n",
    "  # 1. Lookup the embeddings\n",
    "  x = self.embedding(x)\n",
    "  shape_checker(x, 'batch t units')\n",
    "\n",
    "  # 2. Process the target sequence.\n",
    "  x, state = self.rnn(x, initial_state=state)\n",
    "  shape_checker(x, 'batch t units')\n",
    "\n",
    "  # 3. Use the RNN output as the query for the attention over the context.\n",
    "  x = self.attention(x, context)\n",
    "  self.last_attention_weights = self.attention.last_attention_weights\n",
    "  shape_checker(x, 'batch t units')\n",
    "  shape_checker(self.last_attention_weights, 'batch t s')\n",
    "\n",
    "  # Step 4. Generate logit predictions for the next token.\n",
    "  logits = self.output_layer(x)\n",
    "  shape_checker(logits, 'batch t target_vocab_size')\n",
    "\n",
    "  if return_state:\n",
    "    return logits, state\n",
    "  else:\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1-mLAcUEXpK"
   },
   "source": [
    "That will be sufficient for training. Create an instance of the decoder to test out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.737178Z",
     "iopub.status.busy": "2022-12-14T13:53:37.736732Z",
     "iopub.status.idle": "2022-12-14T13:53:37.832773Z",
     "shell.execute_reply": "2022-12-14T13:53:37.832171Z"
    },
    "id": "4ZUMbYXIEVeA"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(target_text_processor, UNITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFWaI4wqzt4t"
   },
   "source": [
    "In training you'll use the decoder like this:\n",
    "\n",
    "Given the context and target tokens, for each target token it predicts the next target token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.836650Z",
     "iopub.status.busy": "2022-12-14T13:53:37.835861Z",
     "iopub.status.idle": "2022-12-14T13:53:37.896769Z",
     "shell.execute_reply": "2022-12-14T13:53:37.896077Z"
    },
    "id": "5YM-lD7bzx18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder output shape: (batch, s, units) (64, 22, 256)\n",
      "input target tokens shape: (batch, t) (64, 20)\n",
      "logits shape shape: (batch, target_vocabulary_size) (64, 20, 5000)\n"
     ]
    }
   ],
   "source": [
    "logits = decoder(ex_context, ex_tar_in)\n",
    "\n",
    "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
    "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
    "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhS_tbk7VQkX"
   },
   "source": [
    "#### Inference\n",
    "\n",
    "To use it for inference you'll need a couple more methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.900171Z",
     "iopub.status.busy": "2022-12-14T13:53:37.899703Z",
     "iopub.status.idle": "2022-12-14T13:53:37.903500Z",
     "shell.execute_reply": "2022-12-14T13:53:37.902953Z"
    },
    "id": "SPm12cnIVRQr"
   },
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def get_initial_state(self, context):\n",
    "  batch_size = tf.shape(context)[0]\n",
    "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "  embedded = self.embedding(start_tokens)\n",
    "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.906633Z",
     "iopub.status.busy": "2022-12-14T13:53:37.906194Z",
     "iopub.status.idle": "2022-12-14T13:53:37.910082Z",
     "shell.execute_reply": "2022-12-14T13:53:37.909439Z"
    },
    "id": "TzeOhpBvVS5L"
   },
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def tokens_to_text(self, tokens):\n",
    "  words = self.id_to_word(tokens)\n",
    "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
    "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.913203Z",
     "iopub.status.busy": "2022-12-14T13:53:37.912770Z",
     "iopub.status.idle": "2022-12-14T13:53:37.917262Z",
     "shell.execute_reply": "2022-12-14T13:53:37.916636Z"
    },
    "id": "v6ildnz_V1MA"
   },
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
    "  logits, state = self(\n",
    "    context, next_token,\n",
    "    state = state,\n",
    "    return_state=True) \n",
    "  \n",
    "  if temperature == 0.0:\n",
    "    next_token = tf.argmax(logits, axis=-1)\n",
    "  else:\n",
    "    logits = logits[:, -1, :]/temperature\n",
    "    next_token = tf.random.categorical(logits, num_samples=1)\n",
    "\n",
    "  # If a sequence produces an `end_token`, set it `done`\n",
    "  done = done | (next_token == self.end_token)\n",
    "  # Once a sequence is done it only produces 0-padding.\n",
    "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
    "  \n",
    "  return next_token, done, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WiXLrVs-FTE"
   },
   "source": [
    "With those extra functions, you can write a generation loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:37.920422Z",
     "iopub.status.busy": "2022-12-14T13:53:37.920046Z",
     "iopub.status.idle": "2022-12-14T13:53:38.166596Z",
     "shell.execute_reply": "2022-12-14T13:53:38.165918Z"
    },
    "id": "SuehagxL-JBZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'embark descproud desccheaper papers training above payment three descfair specialist',\n",
       "       b'window shirin restart learn err textile descaway beijing mechanism reliance',\n",
       "       b'ge se conviction interpretation desertec system nationality door protect gratify'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the loop variables.\n",
    "next_token, done, state = decoder.get_initial_state(ex_context)\n",
    "tokens = []\n",
    "\n",
    "for n in range(10):\n",
    "  # Run one step.\n",
    "  next_token, done, state = decoder.get_next_token(\n",
    "      ex_context, next_token, done, state, temperature=1.0)\n",
    "  # Add the token to the output.\n",
    "  tokens.append(next_token)\n",
    "\n",
    "# Stack all the tokens together.\n",
    "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
    "\n",
    "# Convert the tokens back to a a string\n",
    "result = decoder.tokens_to_text(tokens)\n",
    "result[:3].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ALTdqCMLGSY"
   },
   "source": [
    "Since the model's untrained, it outputs items from the vocabulary almost uniformly at random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6xyru86m914"
   },
   "source": [
    "## The model\n",
    "\n",
    "Now that you have all the model components, combine them to build the model for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:38.170581Z",
     "iopub.status.busy": "2022-12-14T13:53:38.170022Z",
     "iopub.status.idle": "2022-12-14T13:53:38.175086Z",
     "shell.execute_reply": "2022-12-14T13:53:38.174388Z"
    },
    "id": "WWIyuy71TkJT"
   },
   "outputs": [],
   "source": [
    "class Translator(tf.keras.Model):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def __init__(self, units,\n",
    "               context_text_processor,\n",
    "               target_text_processor):\n",
    "    super().__init__()\n",
    "    # Build the encoder and decoder\n",
    "    encoder = Encoder(context_text_processor, units)\n",
    "    decoder = Decoder(target_text_processor, units)\n",
    "\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def call(self, inputs):\n",
    "    context, x = inputs\n",
    "    context = self.encoder(context)\n",
    "    logits = self.decoder(context, x)\n",
    "\n",
    "    #TODO(b/250038731): remove this\n",
    "    try:\n",
    "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rPi0FkS2iA5"
   },
   "source": [
    "During training the model will be used like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:38.178812Z",
     "iopub.status.busy": "2022-12-14T13:53:38.178363Z",
     "iopub.status.idle": "2022-12-14T13:53:38.359380Z",
     "shell.execute_reply": "2022-12-14T13:53:38.358700Z"
    },
    "id": "8vhjTh84K6Mg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context tokens, shape: (batch, s, units) (64, 22)\n",
      "Target tokens, shape: (batch, t) (64, 20)\n",
      "logits, shape: (batch, t, target_vocabulary_size) (64, 20, 5000)\n"
     ]
    }
   ],
   "source": [
    "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
    "\n",
    "logits = model((ex_context_tok, ex_tar_in))\n",
    "\n",
    "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
    "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
    "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ch_71VbIRfK"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FmzjGmprVmE"
   },
   "source": [
    "For training, you'll want to implement your own masked loss and accuracy functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:38.362806Z",
     "iopub.status.busy": "2022-12-14T13:53:38.362542Z",
     "iopub.status.idle": "2022-12-14T13:53:38.366866Z",
     "shell.execute_reply": "2022-12-14T13:53:38.366216Z"
    },
    "id": "WmTHr5iV3jFr"
   },
   "outputs": [],
   "source": [
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:38.370186Z",
     "iopub.status.busy": "2022-12-14T13:53:38.369665Z",
     "iopub.status.idle": "2022-12-14T13:53:38.373568Z",
     "shell.execute_reply": "2022-12-14T13:53:38.372969Z"
    },
    "id": "nRB1CTmQWOIL"
   },
   "outputs": [],
   "source": [
    "def masked_acc(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "    \n",
    "    match = tf.cast(y_true == y_pred, tf.float32)\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "    \n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f32GuAhw2nXm"
   },
   "source": [
    "Configure the model for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:38.376951Z",
     "iopub.status.busy": "2022-12-14T13:53:38.376399Z",
     "iopub.status.idle": "2022-12-14T13:53:38.405030Z",
     "shell.execute_reply": "2022-12-14T13:53:38.404311Z"
    },
    "id": "9g0DRRvm3l9X"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=masked_loss, \n",
    "              metrics=[masked_acc, masked_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DWLI3pssjnx"
   },
   "source": [
    "The model is randomly initialized, and should give roughly uniform output probabilities. So it's easy to predict what the initial values of the metrics should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:38.408947Z",
     "iopub.status.busy": "2022-12-14T13:53:38.408411Z",
     "iopub.status.idle": "2022-12-14T13:53:38.414979Z",
     "shell.execute_reply": "2022-12-14T13:53:38.414386Z"
    },
    "id": "BuP3_LFENMJG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expected_loss': 8.517193, 'expected_acc': 0.0002}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
    "\n",
    "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
    " \"expected_acc\": 1/vocab_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frVba49Usd0Z"
   },
   "source": [
    "That should roughly match the values returned by running a few steps of evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:38.418259Z",
     "iopub.status.busy": "2022-12-14T13:53:38.417876Z",
     "iopub.status.idle": "2022-12-14T13:53:45.431110Z",
     "shell.execute_reply": "2022-12-14T13:53:45.430452Z"
    },
    "id": "8rJITfxEsHKR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 9s 159ms/step - loss: 8.5254 - masked_acc: 1.8485e-04 - masked_loss: 8.5254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 8.525407791137695,\n",
       " 'masked_acc': 0.0001848475803853944,\n",
       " 'masked_loss': 8.525407791137695}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds, steps=20, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:53:45.434651Z",
     "iopub.status.busy": "2022-12-14T13:53:45.433998Z",
     "iopub.status.idle": "2022-12-14T13:55:54.435494Z",
     "shell.execute_reply": "2022-12-14T13:55:54.434762Z"
    },
    "id": "BQd_esVVoSf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 44s 334ms/step - loss: 5.5860 - masked_acc: 0.1962 - masked_loss: 5.5860 - val_loss: 4.6294 - val_masked_acc: 0.3128 - val_masked_loss: 4.6294\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 3.9800 - masked_acc: 0.4158 - masked_loss: 3.9800 - val_loss: 2.9959 - val_masked_acc: 0.5559 - val_masked_loss: 2.9959\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 36s 362ms/step - loss: 2.3703 - masked_acc: 0.6529 - masked_loss: 2.3703 - val_loss: 1.5111 - val_masked_acc: 0.7931 - val_masked_loss: 1.5111\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.3567 - masked_acc: 0.8103 - masked_loss: 1.3567 - val_loss: 0.9857 - val_masked_acc: 0.8714 - val_masked_loss: 0.9857\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 0.7808 - masked_acc: 0.8997 - masked_loss: 0.7808 - val_loss: 0.6075 - val_masked_acc: 0.9269 - val_masked_loss: 0.6075\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 39s 390ms/step - loss: 0.5573 - masked_acc: 0.9293 - masked_loss: 0.5565 - val_loss: 0.4480 - val_masked_acc: 0.9475 - val_masked_loss: 0.4480\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 39s 386ms/step - loss: 0.4223 - masked_acc: 0.9481 - masked_loss: 0.4223 - val_loss: 0.3934 - val_masked_acc: 0.9548 - val_masked_loss: 0.3934\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 44s 440ms/step - loss: 0.3632 - masked_acc: 0.9563 - masked_loss: 0.3632 - val_loss: 0.4422 - val_masked_acc: 0.9413 - val_masked_loss: 0.4422\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 42s 422ms/step - loss: 0.5517 - masked_acc: 0.9220 - masked_loss: 0.5517 - val_loss: 0.3783 - val_masked_acc: 0.9572 - val_masked_loss: 0.3783\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 45s 449ms/step - loss: 0.3204 - masked_acc: 0.9615 - masked_loss: 0.3204 - val_loss: 0.3250 - val_masked_acc: 0.9626 - val_masked_loss: 0.3250\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 53s 530ms/step - loss: 0.3022 - masked_acc: 0.9643 - masked_loss: 0.3025 - val_loss: 0.3289 - val_masked_acc: 0.9624 - val_masked_loss: 0.3289\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 52s 519ms/step - loss: 0.3115 - masked_acc: 0.9545 - masked_loss: 0.3115 - val_loss: 0.3406 - val_masked_acc: 0.9587 - val_masked_loss: 0.3406\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 0.2471 - masked_acc: 0.9673 - masked_loss: 0.2471 - val_loss: 0.2964 - val_masked_acc: 0.9665 - val_masked_loss: 0.2964\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 55s 546ms/step - loss: 0.2324 - masked_acc: 0.9701 - masked_loss: 0.2324 - val_loss: 0.2757 - val_masked_acc: 0.9682 - val_masked_loss: 0.2757\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 43s 433ms/step - loss: 0.2285 - masked_acc: 0.9698 - masked_loss: 0.2285 - val_loss: 0.2805 - val_masked_acc: 0.9662 - val_masked_loss: 0.2805\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 39s 389ms/step - loss: 0.2475 - masked_acc: 0.9669 - masked_loss: 0.2475 - val_loss: 0.2845 - val_masked_acc: 0.9678 - val_masked_loss: 0.2845\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 42s 423ms/step - loss: 0.2012 - masked_acc: 0.9715 - masked_loss: 0.2008 - val_loss: 0.2993 - val_masked_acc: 0.9634 - val_masked_loss: 0.2993\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds.repeat(), \n",
    "    epochs=100,\n",
    "    steps_per_epoch = 100,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps = 20,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:55:54.439314Z",
     "iopub.status.busy": "2022-12-14T13:55:54.438809Z",
     "iopub.status.idle": "2022-12-14T13:55:54.597838Z",
     "shell.execute_reply": "2022-12-14T13:55:54.596991Z"
    },
    "id": "38rLdlmtQHCm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe93105b460>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('CE/token')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:55:54.601744Z",
     "iopub.status.busy": "2022-12-14T13:55:54.601260Z",
     "iopub.status.idle": "2022-12-14T13:55:54.758966Z",
     "shell.execute_reply": "2022-12-14T13:55:54.758112Z"
    },
    "id": "KkhXRASNG80_",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe93108ff40>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['masked_acc'], label='accuracy')\n",
    "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('CE/token')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU3Ce8M6I3rz"
   },
   "source": [
    "### Translate\n",
    "\n",
    "Now that the model is trained, implement a function to execute the full `text => text` translation. This code is basically identical to the [inference example](#inference) in the [decoder section](#the_decoder), but this also captures the attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:55:54.762645Z",
     "iopub.status.busy": "2022-12-14T13:55:54.762120Z",
     "iopub.status.idle": "2022-12-14T13:55:54.768161Z",
     "shell.execute_reply": "2022-12-14T13:55:54.767292Z"
    },
    "id": "mmgYPCVgEwp_"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "@Translator.add_method\n",
    "def translate(self,\n",
    "              texts, *,\n",
    "              max_length=50,\n",
    "              temperature=0.0):\n",
    "  # Process the input texts\n",
    "  context = self.encoder.convert_input(texts)\n",
    "  batch_size = tf.shape(texts)[0]\n",
    "\n",
    "  # Setup the loop inputs\n",
    "  tokens = []\n",
    "  attention_weights = []\n",
    "  next_token, done, state = self.decoder.get_initial_state(context)\n",
    "\n",
    "  for _ in range(max_length):\n",
    "    # Generate the next token\n",
    "    next_token, done, state = self.decoder.get_next_token(\n",
    "        context, next_token, done,  state, temperature)\n",
    "        \n",
    "    # Collect the generated tokens\n",
    "    tokens.append(next_token)\n",
    "    attention_weights.append(self.decoder.last_attention_weights)\n",
    "    \n",
    "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "      break\n",
    "\n",
    "  # Stack the lists of tokens and attention weights.\n",
    "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
    "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
    "\n",
    "  result = self.decoder.tokens_to_text(tokens)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4XufRntbbva"
   },
   "source": [
    "Here are the two helper methods, used above, to convert tokens to text, and to get the next token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:55:54.771943Z",
     "iopub.status.busy": "2022-12-14T13:55:54.771432Z",
     "iopub.status.idle": "2022-12-14T13:55:54.949359Z",
     "shell.execute_reply": "2022-12-14T13:55:54.948750Z"
    },
    "id": "E5hqvbR5FUCD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xi [UNK] [UNK] '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.translate(['i eat banana']) \n",
    "result[0].numpy().decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHBdOf9duumm"
   },
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:55:57.363465Z",
     "iopub.status.busy": "2022-12-14T13:55:57.363013Z",
     "iopub.status.idle": "2022-12-14T13:55:57.869981Z",
     "shell.execute_reply": "2022-12-14T13:55:57.869292Z"
    },
    "id": "sT68i4jYEQ7q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 91\n",
      "descrefore , xi would descsimply ask that amendment , and to resolution be withdraw .\n",
      "descrefore , xi would descsimply ask that amendment 7 , 8 and 9 to resolution be withdraw .\n",
      "-------------------------------------\n",
      "24 26\n",
      "before vote on paragraph\n",
      "before vote on paragraph 3\n",
      "-------------------------------------\n",
      "70 67\n",
      "xit affect and concern all european , whatever outcome outcome today .\n",
      "xit affect and concern all european , whatever outcome vote today .\n",
      "-------------------------------------\n",
      "121 120\n",
      "xi descrefore think that investment to romanium and bulgarium be use without take into consideration descentire context .\n",
      "xi descrefore think that reference to romanium and bulgarium be use without take into consideration descentire context .\n",
      "-------------------------------------\n",
      "109 117\n",
      "descdemocratic desclegislative institution like european parliament descobviously can question this benefit .\n",
      "descdemocratic desclegislative institution like european parliament descobviously can descnot question this benefit .\n",
      "-------------------------------------\n",
      "94 88\n",
      "what be xwe xposs legitimacy for issue any opinion descwhatsoever on condition italian media ?\n",
      "what be xwe legitimacy for issue any opinion descwhatsoever on condition italian media ?\n",
      "-------------------------------------\n",
      "77 80\n",
      "from entry into force treaty , commission vote will become eu eu delegation .\n",
      "from entry into force treaty , commission delegation will become eu delegation .\n",
      "-------------------------------------\n",
      "89 92\n",
      "as xwe know , desccommon descforeign policy be descnot descjust sum descnational policy .\n",
      "as xwe know , desccommon descforeign policy be descnot descjust sum 27 descnational policy .\n",
      "-------------------------------------\n",
      "41 47\n",
      "speaker agree to take question under rule\n",
      "speaker agree to take question under rule 149 8\n",
      "-------------------------------------\n",
      "98 95\n",
      "xit be descalso reason why this report seek to make commission be descresponsible for everything .\n",
      "xit be descalso reason why this report seek to make commission descresponsible for everything .\n",
      "-------------------------------------\n",
      "84 81\n",
      "xit be descrefore descessential that european parliament xposs report this process .\n",
      "xit be descrefore descessential that european parliament influence this process .\n",
      "-------------------------------------\n",
      "81 87\n",
      "xwe want to take account this , and descalso next week european council meeting .\n",
      "xwe want to take account this , and descalso next week xposs european council meeting .\n",
      "-------------------------------------\n",
      "62 64\n",
      "descsimply have blow diplomacy college be descnot descenough .\n",
      "descsimply have attend diplomacy college be descnot descenough .\n",
      "-------------------------------------\n",
      "82 91\n",
      "in , desconly agenda item in council descforeign minister be debate descpublicly .\n",
      "in 2008 , desconly 1 % agenda item in council descforeign minister be debate descpublicly .\n",
      "-------------------------------------\n",
      "74 76\n",
      "xwe want to set descpolitical priority european union for descst century .\n",
      "xwe want to set descpolitical priority european union for desc21st century .\n",
      "-------------------------------------\n",
      "32 57\n",
      "xwe do descnot agree with this .\n",
      "xwe envisage descdifferent path for europe xposs future .\n",
      "-------------------------------------\n",
      "69 79\n",
      "vote will take place on thursday , october descwritten statement rule\n",
      "vote will take place on thursday , 22 october desc200written statement rule 149\n",
      "-------------------------------------\n",
      "113 119\n",
      "xwe will have descfirst transatlantic desceconomic council with president obama xposs administration on october .\n",
      "xwe will have descfirst transatlantic desceconomic council with president obama xposs administration on 26 27 october .\n",
      "-------------------------------------\n",
      "81 83\n",
      "descshortly after that , on november , descre will be summit between eu and xwe .\n",
      "descshortly after that , on 3 november , descre will be summit between eu and xwe .\n",
      "-------------------------------------\n",
      "79 77\n",
      "cooperation and dialogue in this area be continue and should be spread descup .\n",
      "cooperation and dialogue in this area be continue and should be step descup .\n",
      "-------------------------------------\n",
      "84 75\n",
      "descnow descre be descalso descnew transatlantic desceconomic council xposs report .\n",
      "descnow descre be descalso descnew transatlantic desceconomic council tec .\n",
      "-------------------------------------\n",
      "100 110\n",
      "xit descalso descrightly await role integrate transatlantic market by xi would like answer on that .\n",
      "xit descalso descrightly reiterate role integrate transatlantic market by desc20us would like answer on that .\n",
      "-------------------------------------\n",
      "47 56\n",
      "madam president , in xshe speech , mr malmstr ?\n",
      "m say that action be need , descnot descjust fine word .\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lk/qj1rg14j04l6s3mkk78vj3dw0000gn/T/ipykernel_56374/1442079880.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, texts, max_length, temperature)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Generate the next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     next_token, done, state = self.decoder.get_next_token(\n\u001b[0m\u001b[1;32m     19\u001b[0m         context, next_token, done,  state, temperature)\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lk/qj1rg14j04l6s3mkk78vj3dw0000gn/T/ipykernel_56374/3991468872.py\u001b[0m in \u001b[0;36mget_next_token\u001b[0;34m(self, context, next_token, done, state, temperature)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mDecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_next_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   logits, state = self(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 ):\n\u001b[0;32m-> 1132\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lk/qj1rg14j04l6s3mkk78vj3dw0000gn/T/ipykernel_56374/4219093426.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, context, x, state, return_state)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m# Step 4. Generate logit predictions for the next token.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0mshape_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch t target_vocab_size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 ):\n\u001b[0;32m-> 1132\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/layers/core/dense.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   5138\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5139\u001b[0m     \u001b[0ma_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5140\u001b[0;31m     \u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims_static\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5141\u001b[0m     b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[1;32m   5142\u001b[0m         b, b_axes, True)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_tensordot_reshape\u001b[0;34m(a, axes, flipped)\u001b[0m\n\u001b[1;32m   5055\u001b[0m       \u001b[0mfree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5056\u001b[0m       \u001b[0mfree_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshape_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5057\u001b[0;31m       \u001b[0mprod_free\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5058\u001b[0m       \u001b[0mprod_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5059\u001b[0m       \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfree\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflipped\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfree\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[0;32m-> 3051\u001b[0;31m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[1;32m   3052\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   3053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# count=0\n",
    "\n",
    "# for i in range(len(context_pred)):\n",
    "# #     print(t)\n",
    "#     pred=model.translate([context_pred[i].lower()])[0].numpy().decode()[:-1]\n",
    "#     if '[UNK]' in pred: continue\n",
    "#     target_text=target_pred[i].replace('-','')\n",
    "#     if pred!=target_text:\n",
    "#         print(len(pred),len(target_text))\n",
    "#         count+=1\n",
    "#         print(pred)\n",
    "#         print(target_text)\n",
    "#         print('-------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43855\n"
     ]
    }
   ],
   "source": [
    "print(len(context_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââ| 43855/43855 [4:09:02<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4410\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "out='../data/gloss-text-augmented.txt'\n",
    "num=0\n",
    "with open (out,'a')as f:\n",
    "    for i in tqdm(range(len(context_pred))):\n",
    "#     print(t)\n",
    "        pred=model.translate([context_pred[i].lower()])[0].numpy().decode()[:-1]\n",
    "        if '[UNK]' in pred: continue\n",
    "        target_text=target_pred[i].replace('-','')\n",
    "        if pred!=target_text:\n",
    "            f.write(pred+'\\t'+context_pred[i]+'\\n')\n",
    "            num+=1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4POAuUgLxLv"
   },
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-6cFyqeUPQm"
   },
   "source": [
    "If you want to export this model you'll need to wrap the `translate` method in a `tf.function`. That implementation will get the job done:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:55:58.079687Z",
     "iopub.status.busy": "2022-12-14T13:55:58.078988Z",
     "iopub.status.idle": "2022-12-14T13:55:58.083501Z",
     "shell.execute_reply": "2022-12-14T13:55:58.082908Z"
    },
    "id": "fNhGwQaVKIAy"
   },
   "outputs": [],
   "source": [
    "class Export(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
    "  def translate(self, inputs):\n",
    "    return self.model.translate(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:55:58.086412Z",
     "iopub.status.busy": "2022-12-14T13:55:58.086180Z",
     "iopub.status.idle": "2022-12-14T13:55:58.089508Z",
     "shell.execute_reply": "2022-12-14T13:55:58.088833Z"
    },
    "id": "5Tjqs9FzNwW5"
   },
   "outputs": [],
   "source": [
    "export = Export(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkccvHDvXCa8"
   },
   "source": [
    "Run the `tf.function` once to compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:55:58.092723Z",
     "iopub.status.busy": "2022-12-14T13:55:58.092252Z",
     "iopub.status.idle": "2022-12-14T13:56:58.387146Z",
     "shell.execute_reply": "2022-12-14T13:56:58.386446Z"
    },
    "id": "_NzrixLvVBjQ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = export.translate(tf.constant(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:56:58.390886Z",
     "iopub.status.busy": "2022-12-14T13:56:58.390265Z",
     "iopub.status.idle": "2022-12-14T13:56:58.489134Z",
     "shell.execute_reply": "2022-12-14T13:56:58.488420Z"
    },
    "id": "USJdu00tVFbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrections to votes and voting intentions see minutes                                          \n",
      "the council position at first reading see minutes                                          \n",
      "decisions concerning certain documents see minutes                                            \n",
      "\n",
      "CPU times: user 241 ms, sys: 348 ms, total: 589 ms\n",
      "Wall time: 456 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = export.translate(tf.constant(inputs))\n",
    "\n",
    "print(result[0].numpy().decode())\n",
    "print(result[1].numpy().decode())\n",
    "print(result[2].numpy().decode())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NP2dNtEXJPEL"
   },
   "source": [
    "Now that the function has been traced it can be exported using `saved_model.save`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:56:58.492688Z",
     "iopub.status.busy": "2022-12-14T13:56:58.492102Z",
     "iopub.status.idle": "2022-12-14T13:58:20.957361Z",
     "shell.execute_reply": "2022-12-14T13:58:20.956463Z"
    },
    "id": "OyvxT5V0_X5B"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, embedding_3_layer_call_fn, embedding_3_layer_call_and_return_conditional_losses, embedding_4_layer_call_fn, embedding_4_layer_call_and_return_conditional_losses while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: backtranslator/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: backtranslator/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 2.47 s, total: 1min 11s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.saved_model.save(export, 'backtranslator',\n",
    "                    signatures={'serving_default': export.translate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:58:20.963150Z",
     "iopub.status.busy": "2022-12-14T13:58:20.962332Z",
     "iopub.status.idle": "2022-12-14T13:59:15.828295Z",
     "shell.execute_reply": "2022-12-14T13:59:15.827578Z"
    },
    "id": "-I0j3i3ekOba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 11:39:10.809745: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:10.973416: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:12.045512: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:12.653827: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:12.793223: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:13.328628: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:13.356010: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:18.013130: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:18.028405: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:18.587643: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:18.882517: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:19.441066: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:19.854029: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:19.889858: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:19.903720: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:21.164624: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:21.199835: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:21.215373: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:21.248523: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:21.403408: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:21.646612: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:21.897379: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:22.088189: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:22.106962: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:22.129113: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:22.603901: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:22.618390: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:22.703204: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:22.717073: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:22.898688: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:22.995242: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:23.094427: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:23.248803: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:23.416682: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:23.440283: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:23.654407: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:24.014597: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:24.032006: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 11:39:24.245618: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:24.303728: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:24.321393: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:24.348231: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:24.369631: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:24.520203: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:24.536961: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:24.759502: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:25.175434: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:25.190034: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:25.528885: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:25.544711: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:25.797888: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:25.813474: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:25.906210: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:25.921335: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:25.942931: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:26.208366: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:26.796443: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:26.981883: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:26.995038: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:27.096779: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:27.114027: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:27.126388: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:27.309564: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:27.322678: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:27.609293: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:27.715504: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.077582: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.093289: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.108942: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.122569: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.385535: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.571405: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.590240: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.608534: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.818617: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.898237: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.923929: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:28.940210: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 11:39:29.075630: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:29.159569: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:29.172458: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:29.195362: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:29.258300: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:29.488935: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:29.503881: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:31.164135: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:31.180223: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:31.504772: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:31.518075: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:32.024510: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:32.341382: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:32.623082: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:32.736152: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:32.750981: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.199992: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.216947: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.244208: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.470518: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.525660: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.638917: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.656273: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.701608: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.801421: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.815977: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.863401: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.876821: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:33.997705: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:34.012093: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:34.027163: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:34.040726: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:34.062215: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:34.287788: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:34.302193: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:34.375441: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:35.228533: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:35.744729: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:35.762486: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 11:39:36.045396: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:36.580232: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:36.599557: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:36.944895: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:36.962878: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:36.978733: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:36.997609: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:37.013684: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:37.223522: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:37.239321: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:37.897163: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:37.912653: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:37.929901: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:37.947162: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:37.975708: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:37.991968: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:38.484847: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:38.556096: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:38.570803: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:38.708708: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:38.726023: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:38.750633: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:38.776307: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:38.810633: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:38.826595: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:38.962510: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:38.984355: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:40.488360: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:40.501907: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-01-05 11:39:52.669939: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.670905: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.671704: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.672499: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.673261: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.674034: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.674826: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.675634: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.676424: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.677222: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.678021: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.678812: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.679905: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.680706: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.681490: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.682271: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.683320: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.685290: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.686489: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.687539: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.688440: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.689497: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.690379: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.691170: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.691999: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.692812: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.693614: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.694407: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.695207: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.696180: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.697598: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.698798: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.700069: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.701196: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.702260: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.703541: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.704649: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.705678: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.706571: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.707427: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.708256: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.709068: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.710057: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.710868: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.711630: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.712650: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.714615: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.715376: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.716111: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-01-05 11:39:52.716855: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2000 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 49152 l2_cache_size: 524288 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.8 s, sys: 5.86 s, total: 57.7 s\n",
      "Wall time: 58.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reloaded = tf.saved_model.load('translator')\n",
    "_ = reloaded.translate(tf.constant(inputs)) #warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T13:59:15.831959Z",
     "iopub.status.busy": "2022-12-14T13:59:15.831518Z",
     "iopub.status.idle": "2022-12-14T13:59:15.927724Z",
     "shell.execute_reply": "2022-12-14T13:59:15.927147Z"
    },
    "id": "GXZF__FZXJCm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrections to votes and voting intentions see minutes                                          \n",
      "the council position at first reading see minutes                                          \n",
      "decisions concerning certain documents see minutes                                            \n",
      "\n",
      "CPU times: user 181 ms, sys: 54.2 ms, total: 236 ms\n",
      "Wall time: 75.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = reloaded.translate(tf.constant(inputs))\n",
    "\n",
    "print(result[0].numpy().decode())\n",
    "print(result[1].numpy().decode())\n",
    "print(result[2].numpy().decode())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: colorama in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from sacrebleu) (0.4.5)\n",
      "Requirement already satisfied: lxml in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from sacrebleu) (4.9.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from sacrebleu) (1.21.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: portalocker in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from sacrebleu) (2.6.0)\n",
      "Requirement already satisfied: regex in /Users/juicydoggo/opt/anaconda3/lib/python3.8/site-packages (from sacrebleu) (2022.7.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "metric = datasets.load_metric('sacrebleu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input=context_raw[~is_train].tolist()\n",
    "valid_groundtruth=target_raw[~is_train].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input=[i.lower() for i in valid_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââ| 8711/8711 [00:01<00:00, 5840.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model_predictions=[]\n",
    "predict=model.translate(valid_input)\n",
    "for i in tqdm(range(len(predict))):\n",
    "    model_predictions.append(predict[i].numpy().decode())\n",
    "    valid_groundtruth[i]=[valid_groundtruth[i]]\n",
    "metric.add_batch(predictions=model_predictions, references=valid_groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 38.111250737370774, 'counts': [72656, 46367, 29170, 18509], 'totals': [109806, 101096, 92473, 83987], 'precisions': [66.16760468462562, 45.86432697633932, 31.544342672996443, 22.03793444223511], 'bp': 1.0, 'sys_len': 109806, 'ref_len': 101294}\n"
     ]
    }
   ],
   "source": [
    "print(final_score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "nmt_with_attention.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

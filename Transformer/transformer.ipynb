{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset, load_from_disk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import pipeline\n",
    "from googletrans import Translator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset saved in \"dataset\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk ('./dataset/aslg_pc12')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I push the finetuned model on HuggingFace, to use the model, I use `AutoModelForSeq2SeqLM` to load the model and `AutoTokenizer` to load the tokenizer, so that I can use the model to predict the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"junowhite/transformer_model\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"junowhite/transformer_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the pretrained model T5 is originally for translating from German to English and some other common languages, additionally, our dataset is quite small compared to the dataset used to train T5. Thus, our results sometimes get affected and are translated into other languages such as German. However, recognizing the semantic aspect is still relatively good and qualified enough, we decided to use Translator API to translate those results back to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "translators = Translator()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to use the model, I instantiate a pipeline for translation and pass text to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\Python\\lib\\site-packages\\transformers\\pipelines\\__init__.py:858: UserWarning: \"translation\" task was used, instead of \"translation_XX_to_YY\", defaulting to \"translation_en_to_de\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=model, tokenizer = tokenizer)\n",
    "\n",
    "prediction = []\n",
    "answer = []\n",
    "\n",
    "def testing_data(num_of_examples = 5):\n",
    "  for i in range(num_of_examples):\n",
    "    text = dataset[\"train\"][i][\"gloss\"]\n",
    "    answer.append(dataset[\"train\"][i][\"text\"])\n",
    "    prediction.append(translators.translate(translator(text)[0][\"translation_text\"]).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our predictions: ['cooperation at political , social and technical levels is essential in order to achieve objectives of these .', 'mr president , this brisk report is a positive outcome of the single european union superstatate .', 'england is my mother tongue , but I am not england I am irish .', 'therefore , madam president , I am also applauding to the european institutions to intervene .', 'the expressions of solidarity have come from all four cranes .']\n",
      "The answer: ['cooperation at political , social and technical levels is essential in order to achieve the objective of the ses .\\n', 'mr president , this brok report is positive proof of the emergence of a single european union superstate .\\n', 'english is my mother tongue , but I am not english I am irish .\\n', 'therefore , madam president , I am also appealing to the european institutions to intervene .\\n', 'expressions of solidarity have come from all four corners of the globe .\\n']\n"
     ]
    }
   ],
   "source": [
    "testing_data()\n",
    "print(f'Our predictions: {prediction}')\n",
    "print(f'The answer: {answer}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bea42e1b0e07028483ba0ff26b9b4dc4fa162e9d0ccb6b0507d54b9d42d30653"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

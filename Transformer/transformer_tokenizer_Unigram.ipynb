{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtkaMmL7RaX_",
        "outputId": "2303d50e-3e7f-4838-ba91-19194f4424ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully installed datasets-2.8.0 evaluate-0.4.0 huggingface-hub-0.11.1 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.2 transformers-4.25.1 urllib3-1.25.11 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRlcfbMMSCcT"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0Lo5ym3Rdz_"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "\n",
        "dataset = load_dataset(\"aslg_pc12\")\n",
        "dataset = dataset[\"train\"].train_test_split(train_size=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "aNxlvU2BRgB-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "from collections import defaultdict\n",
        "word_freqs = defaultdict(int)\n",
        "for i in range(0, len(dataset[\"train\"])):\n",
        "  for text in dataset[\"train\"][i][\"gloss\"]:\n",
        "    words_with_offsets = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    for word in new_words:\n",
        "        word_freqs[word] += 1\n",
        "  for text in dataset[\"train\"][i][\"text\"]:\n",
        "    words_with_offsets = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    for word in new_words:\n",
        "        word_freqs[word] += 1\n",
        "for i in range(0, len(dataset[\"test\"])):\n",
        "  for text in dataset[\"test\"][i][\"gloss\"]:\n",
        "    words_with_offsets = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    for word in new_words:\n",
        "        word_freqs[word] += 1\n",
        "  for text in dataset[\"test\"][i][\"text\"]:\n",
        "    words_with_offsets = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    for word in new_words:\n",
        "        word_freqs[word] += 1\n",
        "\n",
        "char_freqs = defaultdict(int)\n",
        "subwords_freqs = defaultdict(int)\n",
        "for word, freq in word_freqs.items():\n",
        "    for i in range(len(word)):\n",
        "        char_freqs[word[i]] += freq\n",
        "        # Loop through the subwords of length at least 2\n",
        "        for j in range(i + 2, len(word) + 1):\n",
        "            subwords_freqs[word[i:j]] += freq\n",
        "\n",
        "# Sort subwords by frequency\n",
        "sorted_subwords = sorted(subwords_freqs.items(), key=lambda x: x[1], reverse=True)\n",
        "sorted_subwords[:10]\n",
        "\n",
        "token_freqs = list(char_freqs.items()) + sorted_subwords[: 300 - len(char_freqs)]\n",
        "token_freqs = {token: freq for token, freq in token_freqs}\n",
        "\n",
        "from math import log\n",
        "\n",
        "total_sum = sum([freq for token, freq in token_freqs.items()])\n",
        "model = {token: -log(freq / total_sum) for token, freq in token_freqs.items()}\n",
        "\n",
        "def encode_word(word, model):\n",
        "    best_segmentations = [{\"start\": 0, \"score\": 1}] + [\n",
        "        {\"start\": None, \"score\": None} for _ in range(len(word))\n",
        "    ]\n",
        "    for start_idx in range(len(word)):\n",
        "        # This should be properly filled by the previous steps of the loop\n",
        "        best_score_at_start = best_segmentations[start_idx][\"score\"]\n",
        "        for end_idx in range(start_idx + 1, len(word) + 1):\n",
        "            token = word[start_idx:end_idx]\n",
        "            if token in model and best_score_at_start is not None:\n",
        "                score = model[token] + best_score_at_start\n",
        "                # If we have found a better segmentation ending at end_idx, we update\n",
        "                if (\n",
        "                    best_segmentations[end_idx][\"score\"] is None\n",
        "                    or best_segmentations[end_idx][\"score\"] > score\n",
        "                ):\n",
        "                    best_segmentations[end_idx] = {\"start\": start_idx, \"score\": score}\n",
        "\n",
        "    segmentation = best_segmentations[-1]\n",
        "    if segmentation[\"score\"] is None:\n",
        "        # We did not find a tokenization of the word -> unknown\n",
        "        return [\"<unk>\"], None\n",
        "\n",
        "    score = segmentation[\"score\"]\n",
        "    start = segmentation[\"start\"]\n",
        "    end = len(word)\n",
        "    tokens = []\n",
        "    while start != 0:\n",
        "        tokens.insert(0, word[start:end])\n",
        "        next_start = best_segmentations[start][\"start\"]\n",
        "        end = start\n",
        "        start = next_start\n",
        "    tokens.insert(0, word[start:end])\n",
        "    return tokens, score\n",
        "def compute_loss(model):\n",
        "    loss = 0\n",
        "    for word, freq in word_freqs.items():\n",
        "        _, word_loss = encode_word(word, model)\n",
        "        loss += freq * word_loss\n",
        "    return loss\n",
        "\n",
        "import copy\n",
        "\n",
        "\n",
        "def compute_scores(model):\n",
        "    scores = {}\n",
        "    model_loss = compute_loss(model)\n",
        "    for token, score in model.items():\n",
        "        # We always keep tokens of length 1\n",
        "        if len(token) == 1:\n",
        "            continue\n",
        "        model_without_token = copy.deepcopy(model)\n",
        "        _ = model_without_token.pop(token)\n",
        "        scores[token] = compute_loss(model_without_token) - model_loss\n",
        "    return scores\n",
        "scores = compute_scores(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "umodtld8RjGx"
      },
      "outputs": [],
      "source": [
        "source_lang = \"gloss\"\n",
        "target_lang = \"text\"\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[source_lang]\n",
        "    targets = examples[target_lang]\n",
        "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "fbd84e8ca91f4445a12fec42baa2cd53",
            "93b5b068b8aa4defaa5da3ad8a699002",
            "0326ade69b1749618da12c32ab02ec14",
            "98940151898343f89230f8b43ae355e4",
            "9125d11b40ba4bc0b55eebe17e69afaf",
            "b8311054778944d49bae352e9502ed20",
            "504083418a534c0b88dc28d1b58799c8",
            "9994324275974b5ba9eeff5d44d45f8c",
            "fc24c97d9fec4d45a0fbaa9460c9c1d1",
            "4d3fc39e178742b6928cb7905feda7e8",
            "5ec669b342b04b1cb653a476122779ae",
            "ffe665c41c044a4a9eb17d8a63876200",
            "7ecaedd047fe4f96be4e43bedd91a0a4",
            "79e7a52b7bcc4599a03da08a3cdeb8b2",
            "8443162ead644039a9046aeca46c8b62",
            "b6e2629e800b4ca6985308ac2fa44406",
            "79d00b152fbe44ee96627ed112671bad",
            "cc492e6ca6eb4572a5227a44648d2b0c",
            "f036b362c49e449f8d12781382f01927",
            "b52878b47dc74b1a89f640d683703af2",
            "def449299cf844c8b31fade043c69706",
            "e75235294c8349949326d24ffc39687d"
          ]
        },
        "id": "2V6NsgNuRk4E",
        "outputId": "542d4a1f-89b9-4af7-d7ec-f2a636e2a793"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbd84e8ca91f4445a12fec42baa2cd53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/71 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffe665c41c044a4a9eb17d8a63876200",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/18 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_data = dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiNd3MQbRmmt",
        "outputId": "963abce6-25a3-432c-8111-03f4ed2b06b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.8/dist-packages (2.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2022.6.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.8.10)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (1.21.6)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (4.9.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tJFTJiYdRoGi"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "70ZVLcdrRpmp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = sacrebleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJRTU1WFRraj",
        "outputId": "41ea26a0-a458-4018-dd2e-775d873ee162"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/02bc3551ce463fd96bd4c3735822469bace0396d/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/02bc3551ce463fd96bd4c3735822469bace0396d/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "EyFef79PRs2R"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "_pKeByiHRuGX",
        "outputId": "6ac867c0-3dd3-4baa-b5e9-1de41257bde7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13158' max='13158' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13158/13158 36:06, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.144700</td>\n",
              "      <td>0.744925</td>\n",
              "      <td>49.302200</td>\n",
              "      <td>15.629100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.946500</td>\n",
              "      <td>0.628684</td>\n",
              "      <td>54.423200</td>\n",
              "      <td>15.553600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.881000</td>\n",
              "      <td>0.600445</td>\n",
              "      <td>55.619200</td>\n",
              "      <td>15.553800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to transformer_model/checkpoint-13000\n",
            "Configuration saved in transformer_model/checkpoint-13000/config.json\n",
            "Model weights saved in transformer_model/checkpoint-13000/pytorch_model.bin\n",
            "tokenizer config file saved in transformer_model/checkpoint-13000/tokenizer_config.json\n",
            "Special tokens file saved in transformer_model/checkpoint-13000/special_tokens_map.json\n",
            "Deleting older checkpoint [transformer_model/checkpoint-11500] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, gloss. If text, gloss are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 17542\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=13158, training_loss=1.117422225356084, metrics={'train_runtime': 2166.7255, 'train_samples_per_second': 97.153, 'train_steps_per_second': 6.073, 'total_flos': 3200474103152640.0, 'train_loss': 1.117422225356084, 'epoch': 3.0})"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"transformer_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEMJ8A9FcErT",
        "outputId": "d22527c7-5f13-469c-9895-d9456659e19f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'gloss': 'X-I WOULD REMIND X-YOU THAT X-WE DO DESC-NOT HAVE DESC-GENERAL DESC-LEGISLATIVE POWER ON EVERY ISSUE .\\n',\n",
              " 'text': 'i would remind you that we do not have general legislative power on every issue .\\n'}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"][20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "0nRWh0_ycEHm"
      },
      "outputs": [],
      "source": [
        "text = dataset[\"train\"][20][\"gloss\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcHA_CSQU64B"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"transformer_model\")\n",
        "\n",
        "prediction = []\n",
        "answer = []\n",
        "\n",
        "def testing_data():\n",
        "  for i in range(20):\n",
        "    text = dataset[\"train\"][i][\"gloss\"]\n",
        "    answer.append(dataset[\"train\"][i][\"text\"])\n",
        "    prediction.append(translator(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDjerUwsxSOB",
        "outputId": "a1f3cab4-4a22-467d-b3c8-e28072dc5028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[{'translation_text': 'X-I think this is debating that we need to have .'}], [{'translation_text': 'I think it is the same that we have a large area of security .'}], [{'translation_text': 'es ist kein Weg für Kosovo mit Blick auf die SERBIUM X-POSS-Border .'}], [{'translation_text': 'Sehr geehrter Herr Vorsitzender , wir hätten darüber abgestimmt, wen wir das wollen oder nicht .'}], [{'translation_text': 'Diese weltliche Krise ist durch die europäische Integration zerstreut .'}], [{'translation_text': 'GREAT , and we welcome that .'}], [{'translation_text': 'ich ziehe, daß die Abgeordneten auf diesen drei Zielen abstimmen.'}], [{'translation_text': 'PERHAPS Y HAVE NOT read it .'}], [{'translation_text': \"i ask you why you can't be more cooperative about the question of DRUZHBA PIPELINE .\"}], [{'translation_text': 'Die EU-Erarbeitungshilfe im WATER-Sicherheitsbereich hat sich entschlossen, dies zu verwirklichen .'}], [{'translation_text': 'Der Abbau ist recht erkennbar .'}], [{'translation_text': 'BUDGET CALENDAR SEHEN Sie Minus'}], [{'translation_text': 'SMALLHOLDER IN PARTICULAR LACK STAFF zu sein, um kompetent zu werden .'}], [{'translation_text': 'е ааи ааи ааи ааи ааи ааи .'}], [{'translation_text': 'Der Bericht ist in der ordnungsgemäßen Richtlinie .'}], [{'translation_text': 'Niemand in der rtlichkeit sollte dies einhalten .'}], [{'translation_text': 'COMMISSION MUST manage the system and extend its FUNCTIONALity in order to straEAMLINE COST .'}], [{'translation_text': 'DIESE PRICE SOME NATION STATE in EU ist ASPECT, dass es sich um eine ernsthafte Überprüfung und Konsultation .'}], [{'translation_text': 'ich schließe mich der Sitzung des Europäischen Parlaments an .'}], [{'translation_text': 'KREATIONIMMIGRATION LIAISONOFFICERNETWORK'}]]\n",
            "['i think this is a debate that we need to have .\\n', 'however , I think it is a shame that we have excluded large areas of science .\\n', \"there is no way back for kosovo within serbia's borders .\\n\", 'mr president , so we should have had a vote on whether we wanted it or not .\\n', 'this global crisis is aggravated by a crisis of european integration .\\n', 'great , and we welcome that .\\n', 'so I feel that meps have delivered on those two aims .\\n', 'perhaps they have not read it .\\n', 'i asked him why they cannot be more cooperative regarding the issue of the druzhba pipeline .\\n', 'a mapping of eu development assistance in the water sector has been carried out to improve that ongoing dialogue .\\n', 'the debate is closed .\\n', 'budget calendar see minutes\\n', 'smallholders in particular lack the staff to be able to remain competitive .\\n', 'these are tragic situations which must never happen again .\\n', 'the report is moving in the wrong direction .\\n', 'no one on earth could understand that .\\n', 'the commission must manage the interconnection of these systems and expand their functionality in order to streamline costs .\\n', 'this practice of some nation states in the eu is an aspect that should be seriously reviewed and reconsidered .\\n', 'i declare the session of the european parliament adjourned .\\n', 'creation of an immigration liaison officers network \\n']\n"
          ]
        }
      ],
      "source": [
        "testing_data()\n",
        "print(prediction)\n",
        "print(answer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0326ade69b1749618da12c32ab02ec14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9994324275974b5ba9eeff5d44d45f8c",
            "max": 71,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc24c97d9fec4d45a0fbaa9460c9c1d1",
            "value": 71
          }
        },
        "4d3fc39e178742b6928cb7905feda7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "504083418a534c0b88dc28d1b58799c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ec669b342b04b1cb653a476122779ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79d00b152fbe44ee96627ed112671bad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79e7a52b7bcc4599a03da08a3cdeb8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f036b362c49e449f8d12781382f01927",
            "max": 18,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b52878b47dc74b1a89f640d683703af2",
            "value": 18
          }
        },
        "7ecaedd047fe4f96be4e43bedd91a0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79d00b152fbe44ee96627ed112671bad",
            "placeholder": "​",
            "style": "IPY_MODEL_cc492e6ca6eb4572a5227a44648d2b0c",
            "value": "100%"
          }
        },
        "8443162ead644039a9046aeca46c8b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_def449299cf844c8b31fade043c69706",
            "placeholder": "​",
            "style": "IPY_MODEL_e75235294c8349949326d24ffc39687d",
            "value": " 18/18 [00:02&lt;00:00,  9.28ba/s]"
          }
        },
        "9125d11b40ba4bc0b55eebe17e69afaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93b5b068b8aa4defaa5da3ad8a699002": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8311054778944d49bae352e9502ed20",
            "placeholder": "​",
            "style": "IPY_MODEL_504083418a534c0b88dc28d1b58799c8",
            "value": "100%"
          }
        },
        "98940151898343f89230f8b43ae355e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d3fc39e178742b6928cb7905feda7e8",
            "placeholder": "​",
            "style": "IPY_MODEL_5ec669b342b04b1cb653a476122779ae",
            "value": " 71/71 [00:08&lt;00:00,  9.34ba/s]"
          }
        },
        "9994324275974b5ba9eeff5d44d45f8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b52878b47dc74b1a89f640d683703af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6e2629e800b4ca6985308ac2fa44406": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8311054778944d49bae352e9502ed20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc492e6ca6eb4572a5227a44648d2b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "def449299cf844c8b31fade043c69706": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e75235294c8349949326d24ffc39687d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f036b362c49e449f8d12781382f01927": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd84e8ca91f4445a12fec42baa2cd53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93b5b068b8aa4defaa5da3ad8a699002",
              "IPY_MODEL_0326ade69b1749618da12c32ab02ec14",
              "IPY_MODEL_98940151898343f89230f8b43ae355e4"
            ],
            "layout": "IPY_MODEL_9125d11b40ba4bc0b55eebe17e69afaf"
          }
        },
        "fc24c97d9fec4d45a0fbaa9460c9c1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffe665c41c044a4a9eb17d8a63876200": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ecaedd047fe4f96be4e43bedd91a0a4",
              "IPY_MODEL_79e7a52b7bcc4599a03da08a3cdeb8b2",
              "IPY_MODEL_8443162ead644039a9046aeca46c8b62"
            ],
            "layout": "IPY_MODEL_b6e2629e800b4ca6985308ac2fa44406"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
